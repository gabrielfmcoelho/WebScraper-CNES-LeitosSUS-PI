{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd79ac7c-909a-45c2-8d46-ad7775035347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INICIANDO PROCEDIMENTO DE WEB SCRAPING\n",
      "Codigo preparado por Gabriel Coelho\n",
      "Me encontre em: https://www.linkedin.com/in/gabriel--coelho/\n",
      "<><><><><><><><><><><><><><><><><><><>\n",
      "\n",
      "...Criando diretorios\n",
      "> Diretorio temporario ja existente\n",
      "> Diretorio de armazenamento ja existente\n",
      "\n",
      "...Lendo dados\n",
      "> Banco de dados dos municipios do Piaui 2016 a 2022 - OK\n",
      "> Banco de dados dos leitos CNES PI - OK\n",
      "> Planilhar auxiliar detectada...lendo\n",
      "0    220005\n",
      "1    220010\n",
      "2    220020\n",
      "3    220025\n",
      "Name: Geocodigo, dtype: int64\n",
      "\n",
      "...Criando dados auxiliares\n",
      "> Competencias e planilhas auxiliares - OK\n",
      "> Inicio das competencias: 201601, final das competencias: 202212\n",
      "\n",
      "...Analisando dados dos municipios\n",
      "\n",
      "...Iniciando 220005 - Acauã: 1/224\n",
      "---------------------------------\n",
      "---------------------------------\n",
      ">> Salvando dados\n",
      ">>> Dados salvos\n",
      "\n",
      "...Limpando terminal\n",
      "\n",
      "...Iniciando 220010 - Agricolândia: 2/224\n",
      "---------------------------------\n",
      "---------------------------------\n",
      ">> Salvando dados\n",
      ">>> Dados salvos\n",
      "\n",
      "...Limpando terminal\n",
      "\n",
      "...Iniciando 220020 - Água_Branca: 3/224\n",
      "---------------------------------\n",
      "---------------------------------\n",
      ">> Salvando dados\n",
      ">>> Dados salvos\n",
      "\n",
      "...Limpando terminal\n",
      "\n",
      "...Iniciando 220025 - Alagoinha_do_Piauí: 4/224\n",
      "---------------------------------\n",
      "---------------------------------\n",
      ">> Salvando dados\n",
      ">>> Dados salvos\n",
      "\n",
      "...Limpando terminal\n",
      "\n",
      "...Iniciando 220027 - Alegrete_do_Piauí: 5/224\n",
      "---------------------------------\n",
      "\n",
      "...Iniciando Alegrete_do_Piauí - 201601:\n",
      "> Carregando pagina\n",
      ">> Pagina carregada\n",
      "> Explorando a pagina\n",
      ">> Exploração abortada\n",
      "Dataset: Alegrete_do_Piauí - 1/2016 - VAZIO\n",
      "\n",
      "...Iniciando Alegrete_do_Piauí - 201602:\n",
      "> Carregando pagina\n",
      ">> Pagina carregada\n",
      "> Explorando a pagina\n",
      ">> Exploração abortada\n",
      "Dataset: Alegrete_do_Piauí - 2/2016 - VAZIO\n",
      "\n",
      "...Iniciando Alegrete_do_Piauí - 201603:\n",
      "> Carregando pagina\n",
      ">> Pagina carregada\n",
      "> Explorando a pagina\n",
      ">> Exploração abortada\n",
      "Dataset: Alegrete_do_Piauí - 3/2016 - VAZIO\n",
      "\n",
      "...Iniciando Alegrete_do_Piauí - 201604:\n",
      "> Carregando pagina\n",
      ">> Pagina carregada\n",
      "> Explorando a pagina\n",
      ">> Exploração abortada\n",
      "Dataset: Alegrete_do_Piauí - 4/2016 - VAZIO\n",
      "\n",
      "...Iniciando Alegrete_do_Piauí - 201605:\n",
      "> Carregando pagina\n",
      ">> Pagina carregada\n",
      "> Explorando a pagina\n",
      ">> Exploração abortada\n",
      "Dataset: Alegrete_do_Piauí - 5/2016 - VAZIO\n",
      "\n",
      "...Iniciando Alegrete_do_Piauí - 201606:\n",
      "> Carregando pagina\n",
      ">> Pagina carregada\n",
      "> Explorando a pagina\n",
      ">> Exploração abortada\n",
      "Dataset: Alegrete_do_Piauí - 6/2016 - VAZIO\n",
      "\n",
      "...Iniciando Alegrete_do_Piauí - 201607:\n",
      "> Carregando pagina\n",
      ">> Pagina carregada\n",
      "> Explorando a pagina\n",
      ">> Exploração abortada\n",
      "Dataset: Alegrete_do_Piauí - 7/2016 - VAZIO\n",
      "\n",
      "...Iniciando Alegrete_do_Piauí - 201608:\n",
      "> Carregando pagina\n",
      ">> Pagina carregada\n",
      "> Explorando a pagina\n",
      ">> Exploração abortada\n",
      "Dataset: Alegrete_do_Piauí - 8/2016 - VAZIO\n",
      "\n",
      "...Iniciando Alegrete_do_Piauí - 201609:\n",
      "> Carregando pagina\n",
      ">> Pagina carregada\n",
      "> Explorando a pagina\n",
      ">> Exploração abortada\n",
      "Dataset: Alegrete_do_Piauí - 9/2016 - VAZIO\n",
      "\n",
      "...Iniciando Alegrete_do_Piauí - 201610:\n",
      "> Carregando pagina\n",
      ">> Pagina carregada\n",
      "> Explorando a pagina\n",
      ">> Exploração abortada\n",
      "Dataset: Alegrete_do_Piauí - 10/2016 - VAZIO\n",
      "\n",
      "...Iniciando Alegrete_do_Piauí - 201611:\n",
      "> Carregando pagina\n",
      ">> Pagina carregada\n",
      "> Explorando a pagina\n",
      ">> Exploração abortada\n",
      "Dataset: Alegrete_do_Piauí - 11/2016 - VAZIO\n",
      "\n",
      "...Iniciando Alegrete_do_Piauí - 201612:\n",
      "> Carregando pagina\n"
     ]
    }
   ],
   "source": [
    "#print('VERIFICAÇÃO DE DEPENDENCIAS')\n",
    "#print('<><><><><><><><><><><><><><><><><><><>')\n",
    "#!pip install -r requirements.txt\n",
    "#!pip install beautifulsoup4\n",
    "#!pip install requests\n",
    "#!pip install aiohttp\n",
    "#!pip install nest-asyncio\n",
    "#print('<><><><><><><><><><><><><><><><><><><>')\n",
    "\n",
    "# Importando bibliotecas\n",
    "import pandas as pd\n",
    "import requests\n",
    "import urllib.request\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def converter_comp_p_data(i):\n",
    "    \n",
    "    data = str(i)\n",
    "    dia_ficcional = '20'\n",
    "    ano_data = data[:4]\n",
    "    mes_data = data[4:]\n",
    "    data_completa = dia_ficcional + '/' + mes_data + '/' + ano_data \n",
    "    \n",
    "    return data_completa\n",
    "\n",
    "def converter_comp_p_ano(i):\n",
    "    \n",
    "    data = str(i)\n",
    "    ano_data = data[:4]\n",
    "    \n",
    "    return int(ano_data)\n",
    "\n",
    "def converter_comp_p_mes(i):\n",
    "    \n",
    "    data = str(i)\n",
    "    mes_data = data[4:]\n",
    "    \n",
    "    return int(mes_data)\n",
    "\n",
    "colunas_população = []\n",
    "competencias = []\n",
    "ano_inicial = 2016\n",
    "ano_final = 2022\n",
    "mes_inicial = 1\n",
    "mes_final = 12\n",
    "primeira_competencia = True\n",
    "salvar_mun = False\n",
    "contador_auxiliar = 1\n",
    "index_mun = 0\n",
    "\n",
    "dicionario_categorias = {'CIRÚRGICO':'Cirurgico',\n",
    "                        'CLÍNICO':'Clinico',\n",
    "                        'OBSTÉTRICO':'Obstetrico',\n",
    "                        'PEDIATRICO':'Pediatrico',\n",
    "                        'OUTRAS ESPECIALIDADES':'Outras Especialidades',\n",
    "                        'HOSPITAL DIA':'Hospital Dia',\n",
    "                        'COMPLEMENTAR':'Complementar'}\n",
    "\n",
    "for ano_pop in range(ano_inicial, (ano_final+1)):\n",
    "    colunas_população.append(f'População {ano_pop}')\n",
    "\n",
    "nome_colunas_df = ['Competência', 'Ano', 'Mes', 'Código', 'Categoria', 'Descrição', 'Existente', 'SUS', '%Ocupação', 'Geocodigo', 'População']\n",
    "nome_colunas_df_completo = nome_colunas_df + ['País', 'Estado', 'Município', 'Mesoregião', 'Regional de Saúde']\n",
    "\n",
    "path_armazenamento_raiz = './Leitos_CNES_PI'\n",
    "path_armazenamento_mun = path_armazenamento_raiz + '/Municipios'\n",
    "path_auxiliar = './temp_WSS_CNES'\n",
    "path_csv_munpi = 'MunicipiosPI.csv'\n",
    "\n",
    "print('')\n",
    "print('INICIANDO PROCEDIMENTO DE WEB SCRAPING')\n",
    "print('Codigo preparado por Gabriel Coelho')\n",
    "print('Me encontre em: https://www.linkedin.com/in/gabriel--coelho/')\n",
    "print('<><><><><><><><><><><><><><><><><><><>')\n",
    "\n",
    "print('')\n",
    "print('...Criando diretorios')\n",
    "\n",
    "try:\n",
    "    os.makedirs(path_auxiliar)\n",
    "    print('> Diretorio temporario criado')\n",
    "except:\n",
    "    print('> Diretorio temporario ja existente')\n",
    "    \n",
    "try:\n",
    "    os.makedirs(path_armazenamento_mun)\n",
    "    print('> Diretorio de armazenamento criado')\n",
    "except:\n",
    "    print('> Diretorio de armazenamento ja existente')\n",
    "\n",
    "print('')\n",
    "print('...Lendo dados')\n",
    "\n",
    "try:\n",
    "    df_municipios = pd.read_csv(path_csv_munpi)\n",
    "    print('> Banco de dados dos municipios do Piaui 2016 a 2022 - OK')\n",
    "except:\n",
    "    print('> Banco de dados dos municipios do Piaui 2016 a 2022 - FALHOU')\n",
    "\n",
    "try:\n",
    "    df_Leitos_CNES_PI_Completo = pd.read_csv(f'{path_armazenamento_raiz}/Leitos_CNES_PI_Completo.csv')\n",
    "    print('> Banco de dados dos leitos CNES PI - OK')\n",
    "except:\n",
    "    df_Leitos_CNES_PI_Completo = pd.DataFrame(columns=nome_colunas_df)\n",
    "    df_Leitos_CNES_PI_Completo.to_csv(f'{path_armazenamento_raiz}/Leitos_CNES_PI_Completo.csv')\n",
    "    print('> Banco de dados dos leitos CNES PI - Não existente -> Foi Criado')\n",
    "\n",
    "try:\n",
    "    df_pular_mun_lista = pd.read_csv(f'{path_auxiliar}/pular_mun_lista.csv')\n",
    "    print('> Planilhar auxiliar detectada...lendo')\n",
    "    print(df_pular_mun_lista['Geocodigo'])\n",
    "except:\n",
    "    df_pular_mun_lista = pd.DataFrame(columns=['Geocodigo'])\n",
    "    df_pular_mun_lista.to_csv(f'{path_auxiliar}/pular_mun_lista.csv')\n",
    "    print('> Criando planilha auxiliar')\n",
    "\n",
    "print('')\n",
    "print('...Criando dados auxiliares')\n",
    "\n",
    "municipios = list(df_municipios['Geocodigo'])\n",
    "nome_município = list(df_municipios['Município'])\n",
    "dicionario_municipios = dict(zip(municipios, nome_município))\n",
    "\n",
    "try:\n",
    "    for mun in municipios:\n",
    "        for i in range(ano_inicial, (ano_final+1)):\n",
    "            for j in range(mes_inicial, (mes_final+1)):\n",
    "                if len(str(j)) < 2:\n",
    "                    mes = f'0{j}'\n",
    "                else:\n",
    "                    mes = j\n",
    "                ano = f'{i}{mes}'\n",
    "                if primeira_competencia:\n",
    "                    competencias.append(ano)\n",
    "                for key, value in dicionario_municipios.items():\n",
    "                    if (mun == key):\n",
    "                        nome_mun = value\n",
    "                        nome_mun = nome_mun.replace(' ','_')\n",
    "                nome_dataframe = f'df_Leitos_CNES_PI_{nome_mun}_{ano}'\n",
    "                vars()[nome_dataframe] = pd.DataFrame(columns=nome_colunas_df)\n",
    "        primeira_competencia=False\n",
    "    print('> Competencias e planilhas auxiliares - OK')\n",
    "    print(f'> Inicio das competencias: {min(competencias)}, final das competencias: {max(competencias)}')\n",
    "except:\n",
    "    print(print('> Competencias e planilhas auxiliares - FALHOU'))\n",
    "    \n",
    "print('')\n",
    "print('...Analisando dados dos municipios')\n",
    "\n",
    "for mun in municipios:\n",
    "    #try:\n",
    "        pular_mun=False\n",
    "        \n",
    "        for key, value in dicionario_municipios.items():\n",
    "            if (mun == key):\n",
    "                nome_mun = value\n",
    "                nome_mun = nome_mun.replace(' ','_')\n",
    "        \n",
    "        print('')\n",
    "        print(f'...Iniciando {mun} - {nome_mun}: {index_mun+1}/224')\n",
    "        print('---------------------------------')\n",
    "        contador_auxiliar = contador_auxiliar + 1\n",
    "        \n",
    "        for i in competencias:\n",
    "            #try:\n",
    "                \n",
    "                index_atual=0\n",
    "                ultimo_titulo=''\n",
    "                pular_proxima_linha=False\n",
    "                primeiro=True\n",
    "                controlador=True\n",
    "        \n",
    "                informações = ['','','','','','','','','','','']\n",
    "                \n",
    "                for index, row in df_pular_mun_lista.iterrows(): \n",
    "                    if(row['Geocodigo'] == mun):\n",
    "                        #print(f'>> Pulando {nome_mun} - {i}')\n",
    "                        pular_mun = True\n",
    "                        index_atual = index_atual+1\n",
    "                        break\n",
    "                \n",
    "                if(pular_mun):\n",
    "                    continue\n",
    "            \n",
    "                print('')\n",
    "                print(f'...Iniciando {nome_mun} - {i}:')\n",
    "                \n",
    "                try:\n",
    "                    print('> Carregando pagina')\n",
    "                    url = f'http://cnes2.datasus.gov.br/Mod_Ind_Tipo_Leito.asp?VEstado=22&VMun={mun}&VComp={i}'\n",
    "                    pagina = urllib.request.urlopen(url)\n",
    "                    soup = BeautifulSoup(pagina, 'html.parser')\n",
    "                    tabela_bruta = soup.find_all('table')\n",
    "                    tabela_filtrada = tabela_bruta[0].find('table', border=1, width=500, cellpadding=1, align='center')\n",
    "                    print('>> Pagina carregada')\n",
    "                except:\n",
    "                    print('!!!!Problema ao explorar html!!!!  Tentando novamente..' )\n",
    "                    url = f'http://cnes2.datasus.gov.br/Mod_Ind_Tipo_Leito.asp?VEstado=22&VMun={mun}&VComp={i}'\n",
    "                    pagina = urllib.request.urlopen(url)\n",
    "                    soup = BeautifulSoup(pagina, 'html.parser')\n",
    "                    tabela_bruta = soup.find_all('table')\n",
    "                    tabela_filtrada = tabela_bruta[0].find('table', border=1, width=500, cellpadding=1, align='center')\n",
    "                    print('>> Pagina carregada')\n",
    "            \n",
    "                print('> Explorando a pagina')\n",
    "                if (type(tabela_filtrada) == bs4.element.Tag):\n",
    "                    for linha in tabela_filtrada.find_all('tr'):\n",
    "        \n",
    "                        if (not primeiro):\n",
    "                            primeiro=True\n",
    "                            continue\n",
    "        \n",
    "                        if (pular_proxima_linha):\n",
    "                            pular_proxima_linha = (not pular_proxima_linha)\n",
    "                            continue\n",
    "\n",
    "                        titulo_raw = linha.find('td', colspan=3)\n",
    "                        \n",
    "                        if((type(titulo_raw) == bs4.element.Tag) and titulo_raw.text.strip() != ultimo_titulo):\n",
    "                            titulo = titulo_raw.text.strip()\n",
    "                            if(titulo != ultimo_titulo):\n",
    "                                ultimo_titulo = titulo\n",
    "                                pular_proxima_linha=True\n",
    "                                if(controlador):\n",
    "                                    controlador = False\n",
    "                                else:\n",
    "                                    primeiro = False\n",
    "                                continue\n",
    "\n",
    "                        dados = linha.find_all('td')\n",
    "\n",
    "                        if len(dados) > 4:\n",
    "                            break\n",
    "                            \n",
    "                        print('>> Carregando informações')\n",
    "                        informações[0] = converter_comp_p_data(i)\n",
    "                        informações[1] = converter_comp_p_ano(i)\n",
    "                        informações[2] = converter_comp_p_mes(i)\n",
    "                        informações[3] = int(dados[0].text.strip())\n",
    "                        informações[4] = ultimo_titulo\n",
    "                        informações[5] = dados[1].text.strip()\n",
    "                        informações[6] = int(dados[2].text.strip())\n",
    "                        informações[7] = int(dados[3].text.strip())\n",
    "                        informações[8] = round(float((informações[7])/float(informações[6])), 2)\n",
    "                        informações[9] = mun\n",
    "                        informações[10] = '0'\n",
    "\n",
    "                        df_informações = pd.DataFrame([informações], columns=nome_colunas_df)\n",
    "                        vars()[f'df_Leitos_CNES_PI_{nome_mun}_{i}'] = pd.concat([vars()[f'df_Leitos_CNES_PI_{nome_mun}_{i}'], df_informações], ignore_index=True)\n",
    "                        index_atual = index_atual+1\n",
    "                    \n",
    "                    vars()[f'df_Leitos_CNES_PI_{nome_mun}_{i}']['Competência'] = pd.to_datetime(vars()[f'df_Leitos_CNES_PI_{nome_mun}_{i}']['Competência'], format='%d/%m/%Y')\n",
    "\n",
    "                    vars()[f'df_Leitos_CNES_PI_{nome_mun}_{i}']['Categoria'] = vars()[f'df_Leitos_CNES_PI_{nome_mun}_{i}']['Categoria'].map(dicionario_categorias)\n",
    "            \n",
    "                    \n",
    "                    print('>>> Merge com dados do municipio')\n",
    "                    vars()[f'df_Leitos_CNES_PI_{nome_mun}_{i}'] = pd.merge(vars()[f'df_Leitos_CNES_PI_{nome_mun}_{i}'], df_municipios, on=\"Geocodigo\", how=\"left\", suffixes=('_x', '_y'))\n",
    "                    \n",
    "                    print('>>> Identificando total populacional do periodo')\n",
    "                    for index, row in vars()[f'df_Leitos_CNES_PI_{nome_mun}_{i}'].iterrows():\n",
    "                        for pop_ano in range(ano_inicial, (ano_final+1)):\n",
    "                            if (row['Ano'] == pop_ano):\n",
    "                                for index_mun_i, row_mun_i in df_municipios.iterrows():\n",
    "                                    if(row['Geocodigo'] == row_mun_i['Geocodigo']):\n",
    "                                        vars()[f'df_Leitos_CNES_PI_{nome_mun}_{i}'].iloc[index,10] = df_municipios[f'População {pop_ano}'][index_mun_i]\n",
    "                                        break\n",
    "                            else:\n",
    "                                continue\n",
    "                            break\n",
    "\n",
    "                    vars()[f'df_Leitos_CNES_PI_{nome_mun}_{i}'].drop(colunas_população, axis=1, inplace=True)\n",
    "\n",
    "                    #vars()[f'df_Leitos_CNES_PI_{nome_mun}_{i}'].reset_index(inplace=True, drop=True)\n",
    "                    #df_Leitos_CNES_PI_Completo.reset_index(inplace=True, drop=True)\n",
    "                    \n",
    "                    print('>>> Adicionando à planilha completa')\n",
    "                    df_Leitos_CNES_PI_Completo = pd.concat([df_Leitos_CNES_PI_Completo, vars()[f'df_Leitos_CNES_PI_{nome_mun}_{i}']], ignore_index=True)\n",
    "                    \n",
    "                    if salvar_mun:\n",
    "                        print('>>> Salvando planilha especifica')\n",
    "                        \n",
    "                        vars()[f'df_Leitos_CNES_PI_{nome_mun}_{i}'].to_csv(f'./Leitos_CNES_PI/Municipios/Leitos_CNES_PI_{nome_mun}_{i}.csv')\n",
    "\n",
    "                    print(f'Dataset: {nome_mun} - {converter_comp_p_mes(i)}/{converter_comp_p_ano(i)} - OK')\n",
    "                    #clear_output(wait=True)\n",
    "                    \n",
    "                else:\n",
    "                    print('>> Exploração abortada')\n",
    "                    print(f'Dataset: {nome_mun} - {converter_comp_p_mes(i)}/{converter_comp_p_ano(i)} - VAZIO')\n",
    "                    #clear_output(wait=True)\n",
    "                    \n",
    "            \n",
    "        print('---------------------------------')\n",
    "        print('>> Salvando dados')\n",
    "        df_mun = pd.DataFrame([mun], columns=['Geocodigo'])\n",
    "        df_pular_mun_lista = pd.concat([df_pular_mun_lista, df_mun], ignore_index=True)\n",
    "        df_pular_mun_lista = df_pular_mun_lista.loc[:,df_pular_mun_lista.columns.isin(['Geocodigo'])]\n",
    "        df_pular_mun_lista.to_csv(f'{path_auxiliar}/pular_mun_lista.csv')\n",
    "        df_Leitos_CNES_PI_Completo = df_Leitos_CNES_PI_Completo.loc[:,df_Leitos_CNES_PI_Completo.columns.isin(nome_colunas_df_completo)]\n",
    "        df_Leitos_CNES_PI_Completo.sort_values(['Ano', 'Mes', 'Código', 'Geocodigo'],ascending = [True, True, True, True])\n",
    "        df_Leitos_CNES_PI_Completo.to_csv(f'{path_armazenamento_raiz}/Leitos_CNES_PI_Completo.csv')\n",
    "        index_mun = index_mun + 1\n",
    "        print('>>> Dados salvos')\n",
    "        print('')\n",
    "        print('...Limpando terminal')\n",
    "        #clear_output(wait=True)\n",
    "        \n",
    "            #except(e):\n",
    "                #print(e)\n",
    "                #print(f'Dataset: {nome_mun} - {converter_comp_p_mes(i)}/{converter_comp_p_ano(i)} - FALHOU')\n",
    "            \n",
    "    #except(e):\n",
    "        #print(e)\n",
    "        #print(f'Municipio: {nome_mun} - FALHOU')\n",
    "        \n",
    "print('... Finalizando')   \n",
    "df_Leitos_CNES_PI_Completo.to_csv('./Leitos_CNES_PI/Leitos_CNES_PI_Completo.csv')\n",
    "\n",
    "print('<><><><><><><><><><><><><><><><><><><>')\n",
    "\n",
    "print('!!! Finalizado !!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ac2feb-69d9-47a1-a861-5ea0f803092c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc-showcode": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
